{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64cd9bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "\n",
    "# pretrained model\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.applications.xception import preprocess_input\n",
    "from tensorflow.keras.applications.xception import decode_predictions\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35feb42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e44e97",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "The dataset contains around 2500 images of bees and around 2100 images of wasps. \n",
    "\n",
    "The dataset contains separate folders for training and test sets. \n",
    "\n",
    "\n",
    "### Model\n",
    "\n",
    "For this homework we will use Convolutional Neural Network (CNN). Like in the lectures, we'll use Keras.\n",
    "\n",
    "You need to develop the model with following structure:\n",
    "\n",
    "* The shape for input should be `(150, 150, 3)`\n",
    "* Next, create a convolutional layer ([`Conv2D`](https://keras.io/api/layers/convolution_layers/convolution2d/)):\n",
    "    * Use 32 filters\n",
    "    * Kernel size should be `(3, 3)` (that's the size of the filter)\n",
    "    * Use `'relu'` as activation \n",
    "* Reduce the size of the feature map with max pooling ([`MaxPooling2D`](https://keras.io/api/layers/pooling_layers/max_pooling2d/))\n",
    "    * Set the pooling size to `(2, 2)`\n",
    "* Turn the multi-dimensional result into vectors using a [`Flatten`](https://keras.io/api/layers/reshaping_layers/flatten/) layer\n",
    "* Next, add a `Dense` layer with 64 neurons and `'relu'` activation\n",
    "* Finally, create the `Dense` layer with 1 neuron - this will be the output\n",
    "    * The output layer should have an activation - use the appropriate activation for the binary classification case\n",
    "\n",
    "As optimizer use [`SGD`](https://keras.io/api/optimizers/sgd/) with the following parameters:\n",
    "\n",
    "* `SGD(lr=0.002, momentum=0.8)`\n",
    "\n",
    "For clarification about kernel size and max pooling, check [Office Hours](https://www.youtube.com/watch?v=1WRgdBTUaAc).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "443b995c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model\n",
    "cnn = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0c71ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a convolutional layer\n",
    "cnn.add(Conv2D(filters=32, kernel_size=(3, 3), activation=\"relu\", input_shape=(150, 150, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c3f6d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the size of the feature map with max pooling (MaxPooling2D)\n",
    "# Set the pooling size to (2, 2)\n",
    "cnn.add(MaxPool2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0bfd92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the multi-dimensional result into vectors using a Flatten layer\n",
    "cnn.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4800d0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, add a Dense layer with 64 neurons and 'relu' activation\n",
    "cnn.add(Dense(64, activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af26d421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, create the Dense layer with 1 neuron - this will be the output\n",
    "# The output layer should have an activation - use the appropriate activation for the binary classification case\n",
    "cnn.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb991a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As optimizer use SGD with the following parameters:\n",
    "# SGD(lr=0.002, momentum=0.8)\n",
    "optimizer = keras.optimizers.SGD(learning_rate=0.002, momentum=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bea1bf8",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "Since we have a binary classification problem, what is the best loss function for us?\n",
    "\n",
    "* `mean squared error`\n",
    "* __`binary crossentropy`__ -> correct\n",
    "* `categorical crossentropy`\n",
    "* `cosine similarity`\n",
    "\n",
    "> **Note:** since we specify an activation for the output layer, we don't need to set `from_logits=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e55d6c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = keras.losses.BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd2a304",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "What's the number of parameters in the convolutional layer of our model? You can use the `summary` method for that. \n",
    "\n",
    "* 1 \n",
    "* 65\n",
    "* __896__ -> correct\n",
    "* 11214912"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02a093a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 74, 74, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 175232)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                11214912  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,215,873\n",
      "Trainable params: 11,215,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7376107b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "\n",
    "# Compile the model\n",
    "cnn.compile(optimizer=optimizer,\n",
    "              loss=loss,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37658c84",
   "metadata": {},
   "source": [
    "### Generators and Training\n",
    "\n",
    "For the next two questions, use the following data generator for both train and test sets:\n",
    "\n",
    "```python\n",
    "ImageDataGenerator(rescale=1./255)\n",
    "```\n",
    "\n",
    "* We don't need to do any additional pre-processing for the images.\n",
    "* When reading the data from train/test directories, check the `class_mode` parameter. Which value should it be for a binary classification problem?\n",
    "* Use `batch_size=20`\n",
    "* Use `shuffle=True` for both training and test sets. \n",
    "\n",
    "For training use `.fit()` with the following params:\n",
    "\n",
    "```python\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=test_generator\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2edde2c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3677 images belonging to 2 classes.\n",
      "Found 918 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# prepare data for the model\n",
    "\n",
    "# train data\n",
    "train_gen = ImageDataGenerator(rescale=1./255)\n",
    "train_ds = train_gen.flow_from_directory('./data/train/', \n",
    "                    class_mode=\"binary\",\n",
    "                    target_size=(150, 150), \n",
    "                    batch_size=20,\n",
    "                    shuffle=True)\n",
    "# test data\n",
    "test_gen = ImageDataGenerator(rescale=1./255)\n",
    "test_ds = test_gen.flow_from_directory('./data/test/', \n",
    "                    class_mode=\"binary\",\n",
    "                    target_size=(150, 150), \n",
    "                    batch_size=20,\n",
    "                    shuffle=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3354794c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bee': 0, 'wasp': 1}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check classes\n",
    "train_ds.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b28203cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 150, 150, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the shape of X input\n",
    "next(train_ds)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2462c1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "# np.random.seed(RANDOM_SEED)\n",
    "# random.seed(RANDOM_SEED)\n",
    "keras.utils.set_random_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7f56f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-19 22:10:15.670650: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2023-11-19 22:10:16.300238: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-11-19 22:10:16.300740: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-11-19 22:10:16.300773: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2023-11-19 22:10:16.301264: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-11-19 22:10:16.301356: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 10s 44ms/step - loss: 0.6824 - accuracy: 0.5572 - val_loss: 0.6362 - val_accuracy: 0.6209\n",
      "Epoch 2/10\n",
      "184/184 [==============================] - 8s 43ms/step - loss: 0.6279 - accuracy: 0.6397 - val_loss: 0.5790 - val_accuracy: 0.7157\n",
      "Epoch 3/10\n",
      "184/184 [==============================] - 8s 42ms/step - loss: 0.5773 - accuracy: 0.6998 - val_loss: 0.5438 - val_accuracy: 0.7233\n",
      "Epoch 4/10\n",
      "184/184 [==============================] - 8s 43ms/step - loss: 0.5389 - accuracy: 0.7386 - val_loss: 0.5402 - val_accuracy: 0.7200\n",
      "Epoch 5/10\n",
      "184/184 [==============================] - 8s 42ms/step - loss: 0.5117 - accuracy: 0.7593 - val_loss: 0.5949 - val_accuracy: 0.6928\n",
      "Epoch 6/10\n",
      "184/184 [==============================] - 8s 42ms/step - loss: 0.4990 - accuracy: 0.7696 - val_loss: 0.5085 - val_accuracy: 0.7451\n",
      "Epoch 7/10\n",
      "184/184 [==============================] - 8s 43ms/step - loss: 0.4664 - accuracy: 0.7952 - val_loss: 0.5887 - val_accuracy: 0.7081\n",
      "Epoch 8/10\n",
      "184/184 [==============================] - 8s 42ms/step - loss: 0.4352 - accuracy: 0.8115 - val_loss: 0.5129 - val_accuracy: 0.7516\n",
      "Epoch 9/10\n",
      "184/184 [==============================] - 8s 43ms/step - loss: 0.4116 - accuracy: 0.8224 - val_loss: 0.4849 - val_accuracy: 0.7767\n",
      "Epoch 10/10\n",
      "184/184 [==============================] - 8s 43ms/step - loss: 0.3877 - accuracy: 0.8366 - val_loss: 0.5108 - val_accuracy: 0.7462\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "\n",
    "history = cnn.fit(\n",
    "    train_ds,\n",
    "    epochs=10,\n",
    "    validation_data=test_ds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64f7d5b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.6823903918266296,\n",
       "  0.6279281377792358,\n",
       "  0.5773422718048096,\n",
       "  0.5389232039451599,\n",
       "  0.5116524696350098,\n",
       "  0.49900102615356445,\n",
       "  0.4663781523704529,\n",
       "  0.43523722887039185,\n",
       "  0.41161584854125977,\n",
       "  0.38767746090888977],\n",
       " 'accuracy': [0.5572477579116821,\n",
       "  0.639651894569397,\n",
       "  0.6997552514076233,\n",
       "  0.738645613193512,\n",
       "  0.7593146562576294,\n",
       "  0.7696491479873657,\n",
       "  0.7952134609222412,\n",
       "  0.811531126499176,\n",
       "  0.8224095702171326,\n",
       "  0.8365515470504761],\n",
       " 'val_loss': [0.6362471580505371,\n",
       "  0.5790044069290161,\n",
       "  0.5437665581703186,\n",
       "  0.5401648879051208,\n",
       "  0.5949493646621704,\n",
       "  0.5085054039955139,\n",
       "  0.5886616110801697,\n",
       "  0.5128922462463379,\n",
       "  0.48492664098739624,\n",
       "  0.5107535123825073],\n",
       " 'val_accuracy': [0.6209150552749634,\n",
       "  0.7156862616539001,\n",
       "  0.7233115434646606,\n",
       "  0.7200435996055603,\n",
       "  0.6928104758262634,\n",
       "  0.7450980544090271,\n",
       "  0.7080609798431396,\n",
       "  0.7516340017318726,\n",
       "  0.7766884565353394,\n",
       "  0.7461873888969421]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239b8b82",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "What is the median of training accuracy for all the epochs for this model?\n",
    "\n",
    "* 0.20\n",
    "* 0.40\n",
    "* 0.60\n",
    "* 0.80 -> approximate result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "70af403c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7644819021224976"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(history.history['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19aea6ff",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "What is the standard deviation of training loss for all the epochs for this model?\n",
    "\n",
    "* 0.031\n",
    "* 0.061\n",
    "* __0.091__ -> approx \n",
    "* 0.131"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b7926192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09006098124296918"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(history.history[\"loss\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd1a615",
   "metadata": {},
   "source": [
    "### Data Augmentation\n",
    "\n",
    "For the next two questions, we'll generate more data using data augmentations. \n",
    "\n",
    "Add the following augmentations to your training data generator:\n",
    "\n",
    "* `rotation_range=50,`\n",
    "* `width_shift_range=0.1,`\n",
    "* `height_shift_range=0.1,`\n",
    "* `zoom_range=0.1,`\n",
    "* `horizontal_flip=True,`\n",
    "* `fill_mode='nearest'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "926cb62f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3677 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# re-generate train data with Data Augmentation\n",
    "train_gen = ImageDataGenerator(rescale=1./255,\n",
    "                            rotation_range=50,\n",
    "                            width_shift_range=0.1,\n",
    "                            height_shift_range=0.1,\n",
    "                            zoom_range=0.1,\n",
    "                            horizontal_flip=True,\n",
    "                            fill_mode='nearest'\n",
    "                            )\n",
    "train_ds = train_gen.flow_from_directory('./data/train/', \n",
    "                    class_mode=\"binary\",\n",
    "                    target_size=(150, 150), \n",
    "                    batch_size=20,\n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f15f7c",
   "metadata": {},
   "source": [
    "### Question 5 \n",
    "\n",
    "Let's train our model for 10 more epochs using the same code as previously.\n",
    "> **Note:** make sure you don't re-create the model - we want to continue training the model\n",
    "we already started training.\n",
    "\n",
    "What is the mean of test loss for all the epochs for the model trained with augmentations?\n",
    "\n",
    "* 0.18\n",
    "* __0.48__ -> correct\n",
    "* 0.78\n",
    "* 0.108"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5d719e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "184/184 [==============================] - 22s 121ms/step - loss: 0.4904 - accuracy: 0.7713 - val_loss: 0.4615 - val_accuracy: 0.7930\n",
      "Epoch 2/10\n",
      "184/184 [==============================] - 22s 122ms/step - loss: 0.4920 - accuracy: 0.7764 - val_loss: 0.4812 - val_accuracy: 0.7723\n",
      "Epoch 3/10\n",
      "184/184 [==============================] - 22s 122ms/step - loss: 0.4764 - accuracy: 0.7781 - val_loss: 0.4947 - val_accuracy: 0.7810\n",
      "Epoch 4/10\n",
      "184/184 [==============================] - 22s 122ms/step - loss: 0.4721 - accuracy: 0.7813 - val_loss: 0.4664 - val_accuracy: 0.7952\n",
      "Epoch 5/10\n",
      "184/184 [==============================] - 22s 122ms/step - loss: 0.4722 - accuracy: 0.7857 - val_loss: 0.4822 - val_accuracy: 0.7756\n",
      "Epoch 6/10\n",
      "184/184 [==============================] - 22s 122ms/step - loss: 0.4710 - accuracy: 0.7849 - val_loss: 0.5034 - val_accuracy: 0.7702\n",
      "Epoch 7/10\n",
      "184/184 [==============================] - 22s 121ms/step - loss: 0.4697 - accuracy: 0.7871 - val_loss: 0.4945 - val_accuracy: 0.7691\n",
      "Epoch 8/10\n",
      "184/184 [==============================] - 22s 122ms/step - loss: 0.4666 - accuracy: 0.7832 - val_loss: 0.4726 - val_accuracy: 0.7843\n",
      "Epoch 9/10\n",
      "184/184 [==============================] - 22s 122ms/step - loss: 0.4616 - accuracy: 0.7871 - val_loss: 0.4749 - val_accuracy: 0.7854\n",
      "Epoch 10/10\n",
      "184/184 [==============================] - 22s 122ms/step - loss: 0.4553 - accuracy: 0.7936 - val_loss: 0.4689 - val_accuracy: 0.7832\n"
     ]
    }
   ],
   "source": [
    "history2 = cnn.fit(\n",
    "    train_ds,\n",
    "    epochs=10,\n",
    "    validation_data=test_ds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3a87b3c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4727381467819214"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(history2.history[\"val_loss\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e10cc9b",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "What's the average of test accuracy for the last 5 epochs (from 6 to 10)\n",
    "for the model trained with augmentations?\n",
    "\n",
    "* 0.38\n",
    "* 0.58\n",
    "* __0.78__\n",
    "* 0.98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "840c5da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7784313797950745"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(history2.history[\"val_accuracy\"][-5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba52dd93",
   "metadata": {},
   "source": [
    "Try to build the model different way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6737c60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-19 22:50:59.567119: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-19 22:50:59.574027: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-19 22:50:59.574617: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-19 22:50:59.575572: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-19 22:50:59.575919: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-19 22:50:59.576487: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-19 22:50:59.577004: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-19 22:51:00.174800: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-19 22:51:00.175700: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-19 22:51:00.176497: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-19 22:51:00.177210: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13795 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(150, 150, 3))\n",
    "conv = Conv2D(filters=32, kernel_size=(3, 3), activation=\"relu\", input_shape=(150, 150, 3))(inputs)\n",
    "pooling = MaxPool2D(pool_size=(2, 2))(conv)\n",
    "flat = Flatten()(pooling)\n",
    "inner = Dense(64, activation=\"relu\")(flat)\n",
    "outputs = Dense(units=1, activation='sigmoid')(inner)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "optimizer1 = keras.optimizers.SGD(learning_rate=0.002, momentum=0.8)\n",
    "loss1 = keras.losses.BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e235bb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer1,\n",
    "              loss=loss1,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90617990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3677 images belonging to 2 classes.\n",
      "Found 918 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# train data\n",
    "train_gen1 = ImageDataGenerator(rescale=1./255)\n",
    "train_ds1 = train_gen1.flow_from_directory('./data/train/', \n",
    "                    class_mode=\"binary\",\n",
    "                    target_size=(150, 150), \n",
    "                    batch_size=20,\n",
    "                    shuffle=True)\n",
    "# test data\n",
    "test_gen1 = ImageDataGenerator(rescale=1./255)\n",
    "test_ds1 = test_gen1.flow_from_directory('./data/test/', \n",
    "                    class_mode=\"binary\",\n",
    "                    target_size=(150, 150), \n",
    "                    batch_size=20,\n",
    "                    shuffle=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e058a912",
   "metadata": {},
   "source": [
    "### Q.2\n",
    "Number of parameters in Conv2D - 896"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a67a82e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 150, 150, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 74, 74, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 175232)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                11214912  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,215,873\n",
      "Trainable params: 11,215,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60f62873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-19 22:52:11.894750: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2023-11-19 22:52:12.523482: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-11-19 22:52:12.523973: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-11-19 22:52:12.524004: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2023-11-19 22:52:12.524522: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-11-19 22:52:12.524590: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 10s 43ms/step - loss: 0.6851 - accuracy: 0.5600 - val_loss: 0.6343 - val_accuracy: 0.6569\n",
      "Epoch 2/10\n",
      "184/184 [==============================] - 8s 42ms/step - loss: 0.6404 - accuracy: 0.6399 - val_loss: 0.6053 - val_accuracy: 0.6688\n",
      "Epoch 3/10\n",
      "184/184 [==============================] - 8s 43ms/step - loss: 0.6072 - accuracy: 0.6644 - val_loss: 0.5635 - val_accuracy: 0.7211\n",
      "Epoch 4/10\n",
      "184/184 [==============================] - 8s 41ms/step - loss: 0.5543 - accuracy: 0.7343 - val_loss: 0.5296 - val_accuracy: 0.7484\n",
      "Epoch 5/10\n",
      "184/184 [==============================] - 8s 41ms/step - loss: 0.5171 - accuracy: 0.7550 - val_loss: 0.5468 - val_accuracy: 0.7211\n",
      "Epoch 6/10\n",
      "184/184 [==============================] - 8s 42ms/step - loss: 0.4900 - accuracy: 0.7735 - val_loss: 0.5161 - val_accuracy: 0.7538\n",
      "Epoch 7/10\n",
      "184/184 [==============================] - 8s 42ms/step - loss: 0.4676 - accuracy: 0.7968 - val_loss: 0.5192 - val_accuracy: 0.7636\n",
      "Epoch 8/10\n",
      "184/184 [==============================] - 8s 42ms/step - loss: 0.4545 - accuracy: 0.7985 - val_loss: 0.5819 - val_accuracy: 0.7070\n",
      "Epoch 9/10\n",
      "184/184 [==============================] - 8s 42ms/step - loss: 0.4163 - accuracy: 0.8224 - val_loss: 0.4902 - val_accuracy: 0.7691\n",
      "Epoch 10/10\n",
      "184/184 [==============================] - 8s 42ms/step - loss: 0.3949 - accuracy: 0.8352 - val_loss: 0.5465 - val_accuracy: 0.7495\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "history3 = model.fit(\n",
    "    train_ds1,\n",
    "    epochs=10,\n",
    "    validation_data=test_ds1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefcfa5d",
   "metadata": {},
   "source": [
    "### Q.3\n",
    "median of training accuracy for all the epochs for this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "516a2dd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7642099559307098"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(history3.history['accuracy']) # same result 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce81fff4",
   "metadata": {},
   "source": [
    "### Q.4\n",
    "the standard deviation of training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a596b51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09209891809690528"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(history3.history[\"loss\"]) # approx 0.091"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105faaa2",
   "metadata": {},
   "source": [
    "Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b711fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3677 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# re-generate train data with Data Augmentation\n",
    "train_gen2 = ImageDataGenerator(rescale=1./255,\n",
    "                            rotation_range=50,\n",
    "                            width_shift_range=0.1,\n",
    "                            height_shift_range=0.1,\n",
    "                            zoom_range=0.1,\n",
    "                            horizontal_flip=True,\n",
    "                            fill_mode='nearest'\n",
    "                            )\n",
    "train_ds2 = train_gen2.flow_from_directory('./data/train/', \n",
    "                    class_mode=\"binary\",\n",
    "                    target_size=(150, 150), \n",
    "                    batch_size=20,\n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "039e2b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "184/184 [==============================] - 22s 122ms/step - loss: 0.4993 - accuracy: 0.7650 - val_loss: 0.5258 - val_accuracy: 0.7364\n",
      "Epoch 2/10\n",
      "184/184 [==============================] - 22s 121ms/step - loss: 0.4913 - accuracy: 0.7716 - val_loss: 0.5371 - val_accuracy: 0.7407\n",
      "Epoch 3/10\n",
      "184/184 [==============================] - 22s 122ms/step - loss: 0.4869 - accuracy: 0.7756 - val_loss: 0.4965 - val_accuracy: 0.7691\n",
      "Epoch 4/10\n",
      "184/184 [==============================] - 22s 121ms/step - loss: 0.4797 - accuracy: 0.7781 - val_loss: 0.4856 - val_accuracy: 0.7702\n",
      "Epoch 5/10\n",
      "184/184 [==============================] - 22s 121ms/step - loss: 0.4723 - accuracy: 0.7843 - val_loss: 0.5091 - val_accuracy: 0.7691\n",
      "Epoch 6/10\n",
      "184/184 [==============================] - 22s 121ms/step - loss: 0.4703 - accuracy: 0.7849 - val_loss: 0.5433 - val_accuracy: 0.7266\n",
      "Epoch 7/10\n",
      "184/184 [==============================] - 22s 121ms/step - loss: 0.4631 - accuracy: 0.7811 - val_loss: 0.6630 - val_accuracy: 0.6961\n",
      "Epoch 8/10\n",
      "184/184 [==============================] - 22s 120ms/step - loss: 0.4561 - accuracy: 0.7922 - val_loss: 0.4779 - val_accuracy: 0.7941\n",
      "Epoch 9/10\n",
      "184/184 [==============================] - 22s 121ms/step - loss: 0.4573 - accuracy: 0.7852 - val_loss: 0.5173 - val_accuracy: 0.7647\n",
      "Epoch 10/10\n",
      "184/184 [==============================] - 22s 121ms/step - loss: 0.4582 - accuracy: 0.7936 - val_loss: 0.5158 - val_accuracy: 0.7865\n"
     ]
    }
   ],
   "source": [
    "history4 = model.fit(\n",
    "    train_ds2,\n",
    "    epochs=10,\n",
    "    validation_data=test_ds1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e27bf6e",
   "metadata": {},
   "source": [
    " ### Q.5\n",
    " test loss for all the epochs for the model trained with augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0efe39f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5271378576755523"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(history4.history[\"val_loss\"]) # 0.48"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3f9113",
   "metadata": {},
   "source": [
    "### Q.6\n",
    "the average of test accuracy for the last 5 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eda4a4ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7535947680473327"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(history4.history[\"val_accuracy\"][-5:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
