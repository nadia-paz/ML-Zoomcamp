{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "\n",
    "# pretrained model\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.applications.xception import preprocess_input\n",
    "from tensorflow.keras.applications.xception import decode_predictions\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "train_ds = train_gen.flow_from_directory('./clothing-dataset-small/train/', \n",
    "                              target_size=(150, 150), \n",
    "                                batch_size=32)\n",
    "val_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "val_ds = val_gen.flow_from_directory('./clothing-dataset-small/validation/', \n",
    "                              target_size=(150, 150), \n",
    "                                batch_size=32,\n",
    "                                shuffle=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = Xception(\n",
    "                weights='imagenet', \n",
    "                include_top=False,\n",
    "                input_shape=(150, 150, 3)\n",
    ")\n",
    "# use conv.layers of Xception\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(150, 150, 3))\n",
    "base = base_model(inputs, training = False) \n",
    "\n",
    "# add pooling\n",
    "pooling = keras.layers.GlobalAveragePooling2D()\n",
    "vectors = pooling(base)\n",
    "outputs = keras.layers.Dense(10)(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create model\n",
    "def make_model(learning_rate=0.01):\n",
    "    #################\n",
    "    # # base (pre-trained) model\n",
    "    # base_model = Xception(\n",
    "    #                 weights='imagenet', \n",
    "    #                 include_top=False,\n",
    "    #                 input_shape=(150, 150, 3)\n",
    "    # )\n",
    "    # # use conv.layers of Xception\n",
    "    # base_model.trainable = False\n",
    "    \n",
    "    # #########################################\n",
    "    \n",
    "    # inputs = keras.Input(shape=(150, 150, 3))\n",
    "    # base = base_model(inputs, training = False) \n",
    "\n",
    "    # # add pooling\n",
    "    # pooling = keras.layers.GlobalAveragePooling2D()\n",
    "    # vectors = pooling(base)\n",
    "    # outputs = keras.layers.Dense(10)(vectors) # outputs of conv.layers\n",
    "    ####################\n",
    "    \n",
    "    model = keras.Model(inputs, outputs)\n",
    "    \n",
    "    #########################################\n",
    "    \n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    loss = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=loss,\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('model_v1.h5', save_format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "checkpoint = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        \"xception_v1_{epoch:02d}_{val_accuracy:.3f}.h5\",\n",
    "        monitor=\"val_accuracy\",\n",
    "        save_best_only=True,\n",
    "        mode='max'\n",
    ")\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "model = make_model(learning_rate=learning_rate)\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=10,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding more layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create model\n",
    "def make_model(learning_rate=0.01, size_inner=10):\n",
    "    #################\n",
    "    # base (pre-trained) model\n",
    "    base_model = Xception(\n",
    "                    weights='imagenet', \n",
    "                    include_top=False,\n",
    "                    input_shape=(150, 150, 3)\n",
    "    )\n",
    "    # use conv.layers of Xception\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    #########################################\n",
    "    \n",
    "    inputs = keras.Input(shape=(150, 150, 3))\n",
    "    base = base_model(inputs, training = False) \n",
    "\n",
    "    # add pooling\n",
    "    pooling = keras.layers.GlobalAveragePooling2D()\n",
    "    vectors = pooling(base)\n",
    "    # add inner layer\n",
    "    inner = keras.layers.Dense(size_inner, activation=\"relu\")(vectors)\n",
    "    # replace vectors with inner layer's outputs\n",
    "    \n",
    "    outputs = keras.layers.Dense(10)(inner) # outputs of conv.layers\n",
    "    ####################\n",
    "    \n",
    "    model = keras.Model(inputs, outputs)\n",
    "    \n",
    "    #########################################\n",
    "    \n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    loss = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=loss,\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}\n",
    "lr = 0.001\n",
    "# List of learning rates\n",
    "size_inner = [10, 100, 1000]\n",
    "\n",
    "for size in size_inner:\n",
    "    print(lr)\n",
    "    \n",
    "    model = make_model(learning_rate=lr, size_inner=size)\n",
    "    history = model.fit(train_ds, epochs=10, validation_data=val_ds)\n",
    "    scores[size] = history.history\n",
    "    \n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for size, hist in scores.items():\n",
    "    plt.plot(hist[\"val_accuracy\"], label=(\"val=%s\" % size))\n",
    "plt.xticks(np.arange(10))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization and Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
