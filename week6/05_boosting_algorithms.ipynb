{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "import data_prep as dp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Booster and XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process of training boosting models is sequential. First, we train the model, then we use the errors to train the model again and so on.\n",
    "\n",
    "- from [here](https://vitalflux.com/bagging-vs-boosting-machine-learning-methods/)\n",
    "\n",
    "The idea behind boosting is to train a series of weak models and then combine the predictions of those models to create a strong model. Unlike bagging, which trains multiple models independently, boosting trains each new model such that it focuses on correcting the errors made by the previous model. By training a series of weak models and combining their predictions, you can create a strong model that has high accuracy.\n",
    "\n",
    "One of the benefits of using boosting in machine learning is that it can help to improve the accuracy of a classifier. This is because boosting can be used to combine the predictions of a number of different weak classifiers, which can result in a more accurate overall classification. Additionally, boosting can also be used to improve the robustness of a classifier, meaning that it is less likely to be affected by noise or inaccuracies in the data. Boosting can also be used to improve the generalization ability of the classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://vitalflux.com/wp-content/uploads/2022/11/boosting-vs-bagging-differences-examples.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = \\\n",
    "    dp.X_train, dp.X_val, dp.X_test, dp.y_train, dp.y_val, dp.y_test\n",
    "dv = dp.dv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dv.get_feature_names()\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train, feature_names=features)\n",
    "dval = xgb.DMatrix(X_val, label=y_val, feature_names=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters to pass to xgboost\n",
    "xgb_params = {\n",
    "    'eta': 0.3, # learning rate\n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1, # min_samples_leaf\n",
    "\n",
    "    'objective': 'binary:logistic', # specify that we have a binary classification model\n",
    "    'eval_metric': 'auc',\n",
    "    'nthread': 8,\n",
    "    'seed': 1,\n",
    "    'verbosity': 1 # show the process 0, 1, 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.train(xgb_params, dtrain, num_boost_round=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(dval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8181110895836865"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "watchlist = [(dtrain, 'train'), (dval, 'val')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.86730\tval-auc:0.77938\n",
      "[5]\ttrain-auc:0.93086\tval-auc:0.80858\n",
      "[10]\ttrain-auc:0.95447\tval-auc:0.80851\n",
      "[15]\ttrain-auc:0.96554\tval-auc:0.81334\n",
      "[20]\ttrain-auc:0.97464\tval-auc:0.81729\n",
      "[25]\ttrain-auc:0.97953\tval-auc:0.81686\n",
      "[30]\ttrain-auc:0.98579\tval-auc:0.81543\n",
      "[35]\ttrain-auc:0.99011\tval-auc:0.81206\n",
      "[40]\ttrain-auc:0.99421\tval-auc:0.80922\n",
      "[45]\ttrain-auc:0.99548\tval-auc:0.80842\n",
      "[50]\ttrain-auc:0.99653\tval-auc:0.80918\n",
      "[55]\ttrain-auc:0.99765\tval-auc:0.81114\n",
      "[60]\ttrain-auc:0.99817\tval-auc:0.81172\n",
      "[65]\ttrain-auc:0.99887\tval-auc:0.80798\n",
      "[70]\ttrain-auc:0.99934\tval-auc:0.80870\n",
      "[75]\ttrain-auc:0.99965\tval-auc:0.80555\n",
      "[80]\ttrain-auc:0.99979\tval-auc:0.80549\n",
      "[85]\ttrain-auc:0.99988\tval-auc:0.80374\n",
      "[90]\ttrain-auc:0.99993\tval-auc:0.80409\n",
      "[95]\ttrain-auc:0.99996\tval-auc:0.80548\n",
      "[100]\ttrain-auc:0.99998\tval-auc:0.80509\n",
      "[105]\ttrain-auc:0.99999\tval-auc:0.80629\n",
      "[110]\ttrain-auc:1.00000\tval-auc:0.80637\n",
      "[115]\ttrain-auc:1.00000\tval-auc:0.80494\n",
      "[120]\ttrain-auc:1.00000\tval-auc:0.80574\n",
      "[125]\ttrain-auc:1.00000\tval-auc:0.80727\n",
      "[130]\ttrain-auc:1.00000\tval-auc:0.80746\n",
      "[135]\ttrain-auc:1.00000\tval-auc:0.80753\n",
      "[140]\ttrain-auc:1.00000\tval-auc:0.80899\n",
      "[145]\ttrain-auc:1.00000\tval-auc:0.80733\n",
      "[150]\ttrain-auc:1.00000\tval-auc:0.80841\n",
      "[155]\ttrain-auc:1.00000\tval-auc:0.80734\n",
      "[160]\ttrain-auc:1.00000\tval-auc:0.80711\n",
      "[165]\ttrain-auc:1.00000\tval-auc:0.80707\n",
      "[170]\ttrain-auc:1.00000\tval-auc:0.80734\n",
      "[175]\ttrain-auc:1.00000\tval-auc:0.80704\n",
      "[180]\ttrain-auc:1.00000\tval-auc:0.80723\n",
      "[185]\ttrain-auc:1.00000\tval-auc:0.80678\n",
      "[190]\ttrain-auc:1.00000\tval-auc:0.80672\n",
      "[195]\ttrain-auc:1.00000\tval-auc:0.80708\n",
      "[199]\ttrain-auc:1.00000\tval-auc:0.80725\n"
     ]
    }
   ],
   "source": [
    "xgb_params = {\n",
    "    'eta': 0.3, # learning rate\n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1, # min_samples_leaf\n",
    "\n",
    "    'objective': 'binary:logistic', # specify that we have a binary classification model\n",
    "    'eval_metric': 'auc',\n",
    "    'nthread': 8,\n",
    "    'seed': 1,\n",
    "    'verbosity': 1 # show the process 0, 1, 2\n",
    "}\n",
    "model = xgb.train(xgb_params, \n",
    "                    dtrain, \n",
    "                    evals=watchlist, # to print train and val sets auc score\n",
    "                    verbose_eval = 5, # to print out only every 5th step\n",
    "                    num_boost_round=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model with 200 iterations is definetely overfitting. To capture the long output we can use the magic command `%%capture`, it saves the output into a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture output\n",
    "model = xgb.train(xgb_params, \n",
    "                    dtrain, \n",
    "                    evals=watchlist, # to print train and val sets auc score\n",
    "                    verbose_eval = 5, # to print out only every 5th step\n",
    "                    num_boost_round=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.86730\tval-auc:0.77938\n",
      "[5]\ttrain-auc:0.93086\tval-auc:0.80858\n",
      "[10]\ttrain-auc:0.95447\tval-auc:0.80851\n",
      "[15]\ttrain-auc:0.96554\tval-auc:0.81334\n",
      "[20]\ttrain-auc:0.97464\tval-auc:0.81729\n",
      "[25]\ttrain-auc:0.97953\tval-auc:0.81686\n",
      "[30]\ttrain-auc:0.98579\tval-auc:0.81543\n",
      "[35]\ttrain-auc:0.99011\tval-auc:0.81206\n",
      "[40]\ttrain-auc:0.99421\tval-auc:0.80922\n",
      "[45]\ttrain-auc:0.99548\tval-auc:0.80842\n",
      "[50]\ttrain-auc:0.99653\tval-auc:0.80918\n",
      "[55]\ttrain-auc:0.99765\tval-auc:0.81114\n",
      "[60]\ttrain-auc:0.99817\tval-auc:0.81172\n",
      "[65]\ttrain-auc:0.99887\tval-auc:0.80798\n",
      "[70]\ttrain-auc:0.99934\tval-auc:0.80870\n",
      "[75]\ttrain-auc:0.99965\tval-auc:0.80555\n",
      "[80]\ttrain-auc:0.99979\tval-auc:0.80549\n",
      "[85]\ttrain-auc:0.99988\tval-auc:0.80374\n",
      "[90]\ttrain-auc:0.99993\tval-auc:0.80409\n",
      "[95]\ttrain-auc:0.99996\tval-auc:0.80548\n",
      "[100]\ttrain-auc:0.99998\tval-auc:0.80509\n",
      "[105]\ttrain-auc:0.99999\tval-auc:0.80629\n",
      "[110]\ttrain-auc:1.00000\tval-auc:0.80637\n",
      "[115]\ttrain-auc:1.00000\tval-auc:0.80494\n",
      "[120]\ttrain-auc:1.00000\tval-auc:0.80574\n",
      "[125]\ttrain-auc:1.00000\tval-auc:0.80727\n",
      "[130]\ttrain-auc:1.00000\tval-auc:0.80746\n",
      "[135]\ttrain-auc:1.00000\tval-auc:0.80753\n",
      "[140]\ttrain-auc:1.00000\tval-auc:0.80899\n",
      "[145]\ttrain-auc:1.00000\tval-auc:0.80733\n",
      "[150]\ttrain-auc:1.00000\tval-auc:0.80841\n",
      "[155]\ttrain-auc:1.00000\tval-auc:0.80734\n",
      "[160]\ttrain-auc:1.00000\tval-auc:0.80711\n",
      "[165]\ttrain-auc:1.00000\tval-auc:0.80707\n",
      "[170]\ttrain-auc:1.00000\tval-auc:0.80734\n",
      "[175]\ttrain-auc:1.00000\tval-auc:0.80704\n",
      "[180]\ttrain-auc:1.00000\tval-auc:0.80723\n",
      "[185]\ttrain-auc:1.00000\tval-auc:0.80678\n",
      "[190]\ttrain-auc:1.00000\tval-auc:0.80672\n",
      "[195]\ttrain-auc:1.00000\tval-auc:0.80708\n",
      "[199]\ttrain-auc:1.00000\tval-auc:0.80725\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(output.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[0]\\ttrain-auc:0.86730\\tval-auc:0.77938',\n",
       " '[5]\\ttrain-auc:0.93086\\tval-auc:0.80858',\n",
       " '[10]\\ttrain-auc:0.95447\\tval-auc:0.80851',\n",
       " '[15]\\ttrain-auc:0.96554\\tval-auc:0.81334',\n",
       " '[20]\\ttrain-auc:0.97464\\tval-auc:0.81729']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = output.stdout\n",
    "s.split('\\n')[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[0]', 'train-auc:0.86730', 'val-auc:0.77938']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = s.split('\\n')\n",
    "lines[0].split('\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign the list values of the 1st line into variables\n",
    "num_iterations, train_score, val_score = lines[0].split('\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[0]'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the number of iterations\n",
    "num_iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the integer out ouf the string\n",
    "int(num_iterations.strip('[]'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train-auc:0.86730'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the train_score string\n",
    "train_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train-auc', '0.86730']\n",
      "0.86730\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8673"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# turn trains_score into a number\n",
    "print(train_score.split(':'))\n",
    "print(train_score.split(':')[1])\n",
    "float(train_score.split(':')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'val-auc:0.77938'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77938"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(val_score.split(':')[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put everything into a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_xgb_output(output):\n",
    "    ''' \n",
    "    Returns 3 lists: number of iterations, scores for train, scores for validation\n",
    "    '''\n",
    "    iterations = []\n",
    "    train_scores = []\n",
    "    validations_scores = []\n",
    "\n",
    "    # access every line of the code\n",
    "    for line in output.stdout.strip().split('\\n'):\n",
    "        # split the line by tabulation\n",
    "        num_iterations, train_score, val_score = lines[0].split('\\t')\n",
    "        # save numeric values from the strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-zoomcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
